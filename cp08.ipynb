{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第8章ニューラルネットワーク\n",
    "第7章で取り組んだポジネガ分類を題材として、ニューラルネットワークで分類モデルを実装する。なお、この章ではPyTorchやTensorFlow、JAXなどの深層学習フレームワークを活用せよ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 70.単語埋め込みの読み込み\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 1.1291504e-03 -8.9645386e-04  3.1852722e-04 ... -1.5640259e-03\n",
      "  -1.2302399e-04 -8.6307526e-05]\n",
      " [ 7.0312500e-02  8.6914062e-02  8.7890625e-02 ... -4.7607422e-02\n",
      "   1.4465332e-02 -6.2500000e-02]\n",
      " ...\n",
      " [-1.9653320e-02 -9.0820312e-02 -1.9409180e-02 ... -1.6357422e-02\n",
      "  -1.3427734e-02  4.6630859e-02]\n",
      " [ 3.2714844e-02 -3.2226562e-02  3.6132812e-02 ... -8.8500977e-03\n",
      "   2.6977539e-02  1.9042969e-02]\n",
      " [ 4.5166016e-02 -4.5166016e-02 -3.9367676e-03 ...  7.9589844e-02\n",
      "   7.2265625e-02  1.3000488e-02]]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "vocab = list(model.key_to_index.keys())\n",
    "\n",
    "word_to_id = {'<PAD>': 0}\n",
    "id_to_word = {0: '<PAD>'}\n",
    "\n",
    "for i, word in enumerate(vocab, start=1):\n",
    "    word_to_id[word] = i\n",
    "    id_to_word[i] = word\n",
    "\n",
    "embedding_dim = model.vector_size  # 300\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim), dtype=np.float32)\n",
    "\n",
    "for word, idx in word_to_id.items():\n",
    "\n",
    "    if word == '<PAD>':\n",
    "        continue\n",
    "    embedding_matrix[idx] = model[word]\n",
    "\n",
    "print(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 71.データセットの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'hide new secretions from the parental units ', 'label': tensor([0.]), 'input_id': tensor([  5785,     66, 113845,     18,     12,  15095,   1594])}, {'text': 'contains no wit , only labored gags ', 'label': tensor([0.]), 'input_id': tensor([ 3475,    87, 15888,    90, 27695, 42637])}, {'text': 'that loves its characters and communicates something rather beautiful about human nature ', 'label': tensor([1.]), 'input_id': tensor([    4,  5053,    45,  3305, 31647,   348,   904,  2815,    47,  1276,\n",
      "         1964])}, {'text': 'remains utterly satisfied to remain the same throughout ', 'label': tensor([0.]), 'input_id': tensor([  987, 14528,  4941,   873,    12,   208,   898])}, {'text': 'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up ', 'label': tensor([0.]), 'input_id': tensor([    6,    12,  1445, 43789,    12, 10946,    76, 41349,    42])}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def make_data(df):\n",
    "    result = []\n",
    "    for i, line in df.iterrows():\n",
    "        text = line['sentence']\n",
    "        label = float(line['label'])\n",
    "        words = text.split(' ')\n",
    "        input_id = []\n",
    "        for word in words:\n",
    "            if word in word_to_id:\n",
    "                input_id.append(word_to_id[word])\n",
    "        if len(input_id) == 0:\n",
    "            continue\n",
    "        result.append({'text': text, 'label': torch.tensor([label], dtype=torch.float32), 'input_id': torch.tensor(input_id, dtype=torch.long)})\n",
    "    return result\n",
    "\n",
    "df_train = pd.read_csv('cp07-data/SST-2/train.tsv', sep='\\t')\n",
    "df_dev = pd.read_csv('cp07-data/SST-2/dev.tsv', sep='\\t')\n",
    "\n",
    "data_train = make_data(df_train)\n",
    "data_dev = make_data(df_dev)\n",
    "\n",
    "print(data_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 72.Bag of Wordsモデルの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AvgEmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, embedding_matrix, ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix), freeze=True)\n",
    "        self.linear = nn.Linear(embedding_matrix.shape[1], 1)\n",
    "\n",
    "    def forward(self, input_id):\n",
    "        embedding = self.embedding(input_id)\n",
    "        mean_embed = embedding.mean(dim=0)    \n",
    "        return self.linear(mean_embed)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 73.モデルの学習\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66650/66650 [03:31<00:00, 314.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train loss:0.6517127129303631\n",
      "dev loss:0.6569329247630518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66650/66650 [03:31<00:00, 315.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "train loss:0.5933183649263923\n",
      "dev loss:0.6275609674085991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66650/66650 [03:30<00:00, 317.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\n",
      "train loss:0.5529407278199059\n",
      "dev loss:0.604758490278565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66650/66650 [03:28<00:00, 319.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\n",
      "train loss:0.5238418927346619\n",
      "dev loss:0.5870513897688222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66650/66650 [03:27<00:00, 320.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\n",
      "train loss:0.5022094790140043\n",
      "dev loss:0.5729928026851608\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AvgEmbeddingClassifier(embedding_matrix).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(model, data_train):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for item in tqdm.tqdm(data_train):\n",
    "        optimizer.zero_grad()\n",
    "        input_id = item['input_id'].to(device)\n",
    "        label = item['label'].to(device)\n",
    "        logit = model(input_id)\n",
    "        loss = criterion(logit, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "        \n",
    "def dev(model, data_dev):\n",
    "    model.eval()\n",
    "    dev_loss = []\n",
    "    for item in data_dev:\n",
    "        input_id = item['input_id'].to(device)\n",
    "        label = item['label'].to(device)\n",
    "        logit = model(input_id)\n",
    "        loss = criterion(logit, label)\n",
    "        dev_loss.append(loss.item())\n",
    "    return np.mean(dev_loss)\n",
    "\n",
    "for epoch in range(5):\n",
    "    train_loss = train(model, data_train)\n",
    "    dev_loss = dev(model, data_dev)\n",
    "    print(f'epoch:{epoch}\\ntrain loss:{train_loss}\\ndev loss:{dev_loss}')\n",
    "\n",
    "torch.save(model.state_dict(), '/home/yokoyama/nlp-100/models/cp08/73.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 74.モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.7580275229357798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def dev_acc(model, data_dev):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    for item in data_dev:\n",
    "        input_id = item['input_id'].to(device)\n",
    "        label = item['label'].to(device)\n",
    "        preds = (torch.sigmoid(model(input_id)) > 0.5).float()\n",
    "        pred_labels.append(preds.item())\n",
    "        true_labels.append(label.item())\n",
    "    return accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AvgEmbeddingClassifier(embedding_matrix).to(device)\n",
    "model.load_state_dict(torch.load(\"/home/yokoyama/nlp-100/models/cp08/73.pt\"))\n",
    "\n",
    "acc = dev_acc(model, data_dev)\n",
    "print(f'acc:{acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 75.パディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate(data):\n",
    "    data.sort(key=lambda x: len(x['input_id']), reverse=True)\n",
    "\n",
    "    input_ids = [item[\"input_id\"] for item in data]\n",
    "    labels = [item[\"label\"] for item in data]\n",
    "\n",
    "    padded_ids = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    labels = torch.stack(labels)\n",
    "    result = {'input_id': padded_ids, 'label': labels}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 76.ミニバッチ学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 288.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train loss:0.6450534793429803\n",
      "dev acc:0.5894495412844036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 286.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "train loss:0.5739368901364916\n",
      "dev acc:0.7064220183486238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 284.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\n",
      "train loss:0.5279845911267281\n",
      "dev acc:0.7488532110091743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 277.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\n",
      "train loss:0.4965325057993013\n",
      "dev acc:0.7626146788990825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 281.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\n",
      "train loss:0.4741752711958572\n",
      "dev acc:0.7729357798165137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5\n",
      "train loss:0.45777928464354317\n",
      "dev acc:0.7786697247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 278.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6\n",
      "train loss:0.44533418870807784\n",
      "dev acc:0.7752293577981652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 279.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7\n",
      "train loss:0.4356222094621901\n",
      "dev acc:0.7740825688073395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 288.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8\n",
      "train loss:0.4279240795728168\n",
      "dev acc:0.7786697247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 289.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9\n",
      "train loss:0.42160200385222113\n",
      "dev acc:0.7821100917431193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 279.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10\n",
      "train loss:0.4163671706910896\n",
      "dev acc:0.783256880733945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 281.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11\n",
      "train loss:0.4119558104502142\n",
      "dev acc:0.7844036697247706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 286.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12\n",
      "train loss:0.4081896734148965\n",
      "dev acc:0.7844036697247706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 285.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13\n",
      "train loss:0.4049333620832565\n",
      "dev acc:0.783256880733945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 286.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14\n",
      "train loss:0.4020880385839876\n",
      "dev acc:0.7809633027522935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 282.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15\n",
      "train loss:0.39961481612288374\n",
      "dev acc:0.7809633027522935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16\n",
      "train loss:0.3974190500139675\n",
      "dev acc:0.7821100917431193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 285.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17\n",
      "train loss:0.3954647810797936\n",
      "dev acc:0.783256880733945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 290.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18\n",
      "train loss:0.3937086333349469\n",
      "dev acc:0.783256880733945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 281.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19\n",
      "train loss:0.3921314725009398\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 277.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20\n",
      "train loss:0.39067243194127965\n",
      "dev acc:0.7889908256880734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21\n",
      "train loss:0.3893646748089985\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 280.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22\n",
      "train loss:0.3881511412171063\n",
      "dev acc:0.7889908256880734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23\n",
      "train loss:0.387073974561016\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 289.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24\n",
      "train loss:0.3860514767314171\n",
      "dev acc:0.786697247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 276.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25\n",
      "train loss:0.38511744213115695\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 287.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26\n",
      "train loss:0.3842400571030032\n",
      "dev acc:0.7912844036697247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 280.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27\n",
      "train loss:0.3834388077087375\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28\n",
      "train loss:0.38269867465093166\n",
      "dev acc:0.7912844036697247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 284.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29\n",
      "train loss:0.3819918540224569\n",
      "dev acc:0.7901376146788991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 282.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30\n",
      "train loss:0.3813406865340955\n",
      "dev acc:0.7889908256880734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 279.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31\n",
      "train loss:0.3807294530489098\n",
      "dev acc:0.7924311926605505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 285.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32\n",
      "train loss:0.38015882286725566\n",
      "dev acc:0.7935779816513762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 281.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33\n",
      "train loss:0.379603920013528\n",
      "dev acc:0.7924311926605505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 279.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34\n",
      "train loss:0.3791064567223685\n",
      "dev acc:0.7947247706422018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 280.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35\n",
      "train loss:0.3785961291435757\n",
      "dev acc:0.7947247706422018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36\n",
      "train loss:0.37816452617348817\n",
      "dev acc:0.7947247706422018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 281.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37\n",
      "train loss:0.3777206904088083\n",
      "dev acc:0.7935779816513762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 282.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38\n",
      "train loss:0.37733127819164064\n",
      "dev acc:0.7970183486238532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 280.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39\n",
      "train loss:0.3769299524853679\n",
      "dev acc:0.7935779816513762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:40\n",
      "train loss:0.37657448509193875\n",
      "dev acc:0.7958715596330275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 285.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:41\n",
      "train loss:0.3762138281384169\n",
      "dev acc:0.7947247706422018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 284.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:42\n",
      "train loss:0.3759014042477967\n",
      "dev acc:0.7970183486238532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 285.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:43\n",
      "train loss:0.3755786765010896\n",
      "dev acc:0.7958715596330275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 284.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:44\n",
      "train loss:0.3752510964269542\n",
      "dev acc:0.7970183486238532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 285.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:45\n",
      "train loss:0.3749641426268874\n",
      "dev acc:0.7935779816513762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 281.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:46\n",
      "train loss:0.37471434884613886\n",
      "dev acc:0.7958715596330275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 286.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:47\n",
      "train loss:0.37442593834489457\n",
      "dev acc:0.7981651376146789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 283.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:48\n",
      "train loss:0.374194948813747\n",
      "dev acc:0.7970183486238532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:07<00:00, 288.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:49\n",
      "train loss:0.3739545902150557\n",
      "dev acc:0.7970183486238532\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MeanEmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, embedding_matrix, freeze_embedding=True):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix), freeze=freeze_embedding\n",
    "        )\n",
    "        self.linear = nn.Linear(embedding_matrix.shape[1], 1)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        mask = (input_ids != 0).unsqueeze(-1)\n",
    "        embedded = self.embedding(input_ids) * mask\n",
    "        mean_embed = embedded.sum(1) / mask.sum(1).clamp(min=1)\n",
    "        return self.linear(mean_embed).squeeze(1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MeanEmbeddingClassifier(embedding_matrix).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "dev_loader = DataLoader(data_dev, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch in tqdm.tqdm(loader):\n",
    "        input_id = batch['input_id'].to(device)\n",
    "        label = batch['label'].to(device).squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_id)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def dev(model, loader):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    for batch in loader:\n",
    "        input_id = batch['input_id'].to(device)\n",
    "        label = batch['label'].to(device).squeeze(1)\n",
    "        logit = model(input_id)\n",
    "        preds = (torch.sigmoid(logit) > 0.5).float()\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(label.cpu().numpy())\n",
    "    return accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss = train(model, train_loader)\n",
    "    dev_acc = dev(model, dev_loader)\n",
    "    print(f'epoch:{epoch}\\ntrain loss:{train_loss}\\ndev acc:{dev_acc}')\n",
    "\n",
    "torch.save(model.state_dict(), '/home/yokoyama/nlp-100/models/cp08/76.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 77.GPU上での学習\n",
    "76.と同様"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 78.単語埋め込みのファインチューニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train loss:0.5999459676941713\n",
      "dev acc:0.7454128440366973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "train loss:0.42035491369661093\n",
      "dev acc:0.8073394495412844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\n",
      "train loss:0.32645510344538503\n",
      "dev acc:0.8176605504587156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:27<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\n",
      "train loss:0.2797163834458238\n",
      "dev acc:0.8268348623853211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:27<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\n",
      "train loss:0.251293467909484\n",
      "dev acc:0.8245412844036697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5\n",
      "train loss:0.23156868961142968\n",
      "dev acc:0.823394495412844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6\n",
      "train loss:0.21679434004099793\n",
      "dev acc:0.8165137614678899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7\n",
      "train loss:0.20519471702363076\n",
      "dev acc:0.8188073394495413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8\n",
      "train loss:0.1958073860090682\n",
      "dev acc:0.8153669724770642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [04:26<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9\n",
      "train loss:0.18785398108844453\n",
      "dev acc:0.8153669724770642\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MeanEmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, embedding_matrix, freeze_embedding=False):#freeze_embedding=Falseで学習中にembedding層の重みを更新\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            torch.tensor(embedding_matrix), freeze=freeze_embedding\n",
    "        )\n",
    "        self.linear = nn.Linear(embedding_matrix.shape[1], 1)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        mask = (input_ids != 0).unsqueeze(-1)\n",
    "        embedded = self.embedding(input_ids) * mask\n",
    "        mean_embed = embedded.sum(1) / mask.sum(1).clamp(min=1)\n",
    "        return self.linear(mean_embed).squeeze(1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MeanEmbeddingClassifier(embedding_matrix).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "train_loader = DataLoader(data_train, batch_size=32, shuffle=True, collate_fn=collate)\n",
    "dev_loader = DataLoader(data_dev, batch_size=32, shuffle=False, collate_fn=collate)\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch in tqdm.tqdm(loader):\n",
    "        input_id = batch['input_id'].to(device)\n",
    "        label = batch['label'].to(device).squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_id)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def dev(model, loader):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    for batch in loader:\n",
    "        input_id = batch['input_id'].to(device)\n",
    "        label = batch['label'].to(device).squeeze(1)\n",
    "        logit = model(input_id)\n",
    "        preds = (torch.sigmoid(logit) > 0.5).float()\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(label.cpu().numpy())\n",
    "    return accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train(model, train_loader)\n",
    "    dev_acc = dev(model, dev_loader)\n",
    "    print(f'epoch:{epoch}\\ntrain loss:{train_loss}\\ndev acc:{dev_acc}')\n",
    "\n",
    "torch.save(model.state_dict(), '/home/yokoyama/nlp-100/models/cp08/78.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 79.アーキテクチャの変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 107.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "train loss:0.5618758475585907\n",
      "dev acc:0.805045871559633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:18<00:00, 112.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "train loss:0.3752494651754487\n",
      "dev acc:0.7924311926605505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 109.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2\n",
      "train loss:0.3656098894842874\n",
      "dev acc:0.8096330275229358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 109.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3\n",
      "train loss:0.360889786773013\n",
      "dev acc:0.8107798165137615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 108.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4\n",
      "train loss:0.355860928449989\n",
      "dev acc:0.8027522935779816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:18<00:00, 110.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5\n",
      "train loss:0.35824947197578644\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:18<00:00, 109.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6\n",
      "train loss:0.35375129176456654\n",
      "dev acc:0.786697247706422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 108.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7\n",
      "train loss:0.3650477338784369\n",
      "dev acc:0.7878440366972477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 109.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8\n",
      "train loss:0.35630555269569947\n",
      "dev acc:0.7912844036697247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2083/2083 [00:19<00:00, 109.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9\n",
      "train loss:0.3516535079907009\n",
      "dev acc:0.8096330275229358\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "class RNNnet(nn.Module):\n",
    "    def __init__(self, embedding_matrix, hidden_size=64, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix), freeze=True)\n",
    "        self.rnn = nn.RNN(embedding_matrix.shape[1], hidden_size=hidden_size, num_layers=num_layers)\n",
    "        self.linear = nn.Linear(hidden_size*2, 1)\n",
    "\n",
    "    def forward(self, input_id):\n",
    "        embedding = self.embedding(input_id)\n",
    "        embedding = embedding.permute(1,0,2)\n",
    "        output, h_n = self.rnn(embedding)\n",
    "        h_f = h_n[-2]\n",
    "        h_b = h_n[-1]\n",
    "        h = torch.cat([h_f, h_b], dim=1)\n",
    "        return self.linear(h).squeeze(1)\n",
    "\n",
    "\n",
    "def train(model, loader):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    for batch in tqdm.tqdm(loader):\n",
    "        input_id = batch['input_id'].to(device)\n",
    "        label = batch['label'].to(device).squeeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_id)\n",
    "        loss = criterion(logits, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "def dev(model, loader):\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    for batch in loader:\n",
    "        input_id = batch['input_id'].to(device)\n",
    "        label = batch['label'].to(device).squeeze(1)\n",
    "        logit = model(input_id)\n",
    "        preds = (torch.sigmoid(logit) > 0.5).float()\n",
    "        pred_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(label.cpu().numpy())\n",
    "    return accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = RNNnet(embedding_matrix).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss = train(model, train_loader)\n",
    "    dev_acc = dev(model, dev_loader)\n",
    "    print(f'epoch:{epoch}\\ntrain loss:{train_loss}\\ndev acc:{dev_acc}')\n",
    "\n",
    "torch.save(model.state_dict(), '/home/yokoyama/nlp-100/models/cp08/79.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-100",
   "language": "python",
   "name": "nlp-100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
