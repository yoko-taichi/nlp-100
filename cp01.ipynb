{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eee4f434-b083-4ce0-bc70-57f595f96b96",
   "metadata": {},
   "source": [
    "# nlp100本ノック\n",
    "## 第1章：準備運動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c48f3dc-6eb3-47af-a1eb-0002e0e276a8",
   "metadata": {},
   "source": [
    "### p00.文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f37eed96-d5a9-4a42-95dd-882e25e1aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d', 'e', 's', 's', 'e', 'r', 't', 's']\n",
      "desserts\n"
     ]
    }
   ],
   "source": [
    "s = 'stressed'\n",
    "\n",
    "s_reversed_list = list(reversed(s))\n",
    "print(s_reversed_list)\n",
    "\n",
    "s_reversed = ''.join(list(reversed(s)))\n",
    "print(s_reversed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae09a74-fca2-4f8b-9bd4-634ac0272f59",
   "metadata": {},
   "source": [
    "### p01.「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70f125a9-57c8-4ab4-b642-3288ee95198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パトカー\n"
     ]
    }
   ],
   "source": [
    "s = 'パタトクカシー-'\n",
    "\n",
    "s_list = list(s)\n",
    "A = []\n",
    "for i in range(7):\n",
    "    if i % 2 == 0:\n",
    "        A.append(s_list[i])\n",
    "\n",
    "A_join = ''.join(A)\n",
    "print(A_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297de104-4065-4a57-a140-652c37ccd2d5",
   "metadata": {},
   "source": [
    "### p02.「パトカー」＋「タクシー」＝「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "820109eb-b726-41e7-8363-80390a26c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシー-\n"
     ]
    }
   ],
   "source": [
    "B = []\n",
    "C = []\n",
    "for j in range(8):\n",
    "    if j % 2 == 1:\n",
    "        B.append(s_list[j])\n",
    "\n",
    "\n",
    "for k in range(4):\n",
    "    C.append(A[k])\n",
    "    C.append(B[k])\n",
    "\n",
    "print(''.join(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98a856-1c24-471e-aeb9-8df8816afd34",
   "metadata": {},
   "source": [
    "### p03.円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1934f59-dfa3-470e-a805-e2b05fe03cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "text03 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "num_list = []\n",
    "temp_03 = \"\"\n",
    "text03 = text03.replace(\",\", \"\")\n",
    "for ch in text03:\n",
    "    if ch == \" \" or ch == \".\":\n",
    "        num_list.append(len(temp_03))\n",
    "        temp_03 = \"\"\n",
    "    else:\n",
    "        temp_03 += ch\n",
    "\n",
    "print(num_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3745a5a-e478-4f46-b680-4e4bde8c54bf",
   "metadata": {},
   "source": [
    "### p04.元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "197c23a9-4ae0-4218-aca3-1d8ea9a1233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "text04 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "text04 = text04.replace(\".\", \"\")\n",
    "list04 = text04.split(\" \")\n",
    "num_list = {1, 5, 6, 7, 8, 9, 15, 16, 19}\n",
    "dict04 = {}\n",
    "for i, atom in enumerate(list04, 1):\n",
    "    if i not in num_list:\n",
    "        temp = atom[:2]\n",
    "        dict04[temp] = i\n",
    "    else:\n",
    "        temp = atom[0]\n",
    "        dict04[temp] = i\n",
    "print(dict04)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9b176-408c-4ec1-afd3-e76d4e61f0aa",
   "metadata": {},
   "source": [
    "## p05.n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f24586-9ba1-443d-af18-862f1e56ec45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字： ['Ia', 'am', 'ma', 'an', 'nN', 'NL', 'LP', 'Pe', 'er', 'r']\n",
      "単語： [['I', 'am'], ['am', 'an'], ['an', 'NLPer'], ['NLPer']]\n"
     ]
    }
   ],
   "source": [
    "def n_gram(n, text05):\n",
    "    char = text05.replace(\" \", \"\")\n",
    "    word = text05.split(\" \")\n",
    "    char_list = []\n",
    "    word_list = []\n",
    "    for ch in range(len(char)):\n",
    "        char_list.append(char[ch:n+ch])\n",
    "    for wch in range(len(word)):\n",
    "        word_list.append(word[wch:n+wch])\n",
    "\n",
    "    return char_list, word_list\n",
    "\n",
    "c, w = n_gram(2, \"I am an NLPer\")\n",
    "print(\"文字：\", c)\n",
    "print(\"単語：\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d00b78-8d84-4bc4-a18f-2311925036eb",
   "metadata": {},
   "source": [
    "### p06.集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a5ce684-a00a-49e6-8d16-781244d9eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合： {'ag', 'h', 'ra', 'se', 'gr', 'ar', 'ph', 'ad', 'ap', 'e', 'is', 'pa', 'di'}\n",
      "積集合： {'ar', 'pa', 'ra', 'ap'}\n",
      "差集合： {'di', 'ad', 'e', 'is', 'se'}\n",
      "Xのみに含まれる\n"
     ]
    }
   ],
   "source": [
    "text06_a = \"paraparaparadise\"\n",
    "text06_b = \"paragraph\"\n",
    "a_bi, _ = n_gram(2, text06_a)\n",
    "b_bi, _ = n_gram(2, text06_b)\n",
    "X = set(a_bi)\n",
    "Y = set(b_bi)\n",
    "print(\"和集合：\", X | Y)\n",
    "print(\"積集合：\", X & Y)\n",
    "print(\"差集合：\", X - Y)\n",
    "\n",
    "attentionWord = \"se\"\n",
    "if attentionWord in X and attentionWord in Y:\n",
    "    print(\"XおよびYに含まれる\")\n",
    "elif attentionWord in X:\n",
    "    print(\"Xのみに含まれる\")\n",
    "elif attentionWord in Y:\n",
    "    print(\"Yのみに含まれる\")\n",
    "else:\n",
    "    print(\"XとYに含まれない\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4add08-a98e-4bdd-8f3b-721c4d9bd900",
   "metadata": {},
   "source": [
    "### p07.テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad3a07b7-2194-4806-9d6a-179dcc1260d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def Template(x, y, z):\n",
    "    temp = str(x) + \"時の\" + str(y) + \"は\" + str(z)\n",
    "    return temp\n",
    "\n",
    "result = Template(12, \"気温\", 22.4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a51877-a7b8-47e4-b27d-b08df3cc973a",
   "metadata": {},
   "source": [
    "### p08.暗号文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b09dc64-0bac-425d-9249-058f0de077c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "暗号化： gsv jfrxp yildm ulc qfnkh levi gsv ozab wlt\n",
      "複合化： the quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def cipher(text):\n",
    "    repatter = re.compile('[a-z]')\n",
    "    temp = \"\"\n",
    "    for ch in text:\n",
    "        if re.match(repatter, ch):\n",
    "            ch = chr(219 - ord(ch))\n",
    "        temp += ch\n",
    "\n",
    "    return temp\n",
    "\n",
    "encode = cipher(\"the quick brown fox jumps over the lazy dog\")\n",
    "print(\"暗号化：\", encode)\n",
    "decode = cipher(encode)\n",
    "print(\"複合化：\", decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a58211-fdeb-4ed7-bb71-caa99daf29d7",
   "metadata": {},
   "source": [
    "### p09.Typoglycemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d481f734-894c-4b9d-96b8-54c232df1a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cunodl’t bveelie that I cluod aaulctly unerdastnd what I was rdiaeng : the pnhenamoel poewr of the human mind .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "text09 = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n",
    "text09 = text09.replace(\".\", \"\")\n",
    "text09_a = text09.split(\" \")\n",
    "temp = \"\"\n",
    "for txt in text09_a:\n",
    "    if len(txt) <= 4:\n",
    "        pass\n",
    "    else:\n",
    "        txt = txt[0]+\"\".join(random.sample(txt[1:-1], len(txt[1:-1])))+txt[-1]\n",
    "    temp += txt + \" \"\n",
    "result = temp[:-1] + \".\"\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf902c4-7a99-4fef-a437-b8afd6e7d1fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
